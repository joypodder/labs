{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8cde7f",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca3912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c73dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28458.83984375, 12261.189453125, 5443.95458984375, 2574.723388671875, 1367.118896484375, 858.8562622070312, 644.9304809570312, 554.8838500976562, 516.97607421875, 501.0118713378906, 494.283203125, 491.441650390625, 490.2364196777344, 489.7193298339844, 489.4923400878906, 489.3873596191406, 489.33349609375, 489.3016052246094, 489.2781677246094, 489.259033203125, 489.24127197265625, 489.224609375, 489.2081604003906, 489.19158935546875, 489.17535400390625, 489.15911865234375, 489.14288330078125, 489.126220703125, 489.1097106933594, 489.0936584472656, 489.077392578125, 489.0608825683594, 489.04486083984375, 489.02850341796875, 489.01226806640625, 488.99609375, 488.98004150390625, 488.96331787109375, 488.947509765625, 488.93109130859375, 488.9150390625, 488.89898681640625, 488.8829040527344, 488.8666076660156, 488.850341796875, 488.83428955078125, 488.81805419921875, 488.80224609375, 488.7861328125, 488.77008056640625, 488.75384521484375, 488.73797607421875, 488.721923828125, 488.7059020996094, 488.6898498535156, 488.6739807128906, 488.65753173828125, 488.64178466796875, 488.62603759765625, 488.6099548339844, 488.5939025878906, 488.578125, 488.5621643066406, 488.5458984375, 488.53033447265625, 488.51458740234375, 488.49853515625, 488.4828186035156, 488.46661376953125, 488.45098876953125, 488.43505859375, 488.41925048828125, 488.40350341796875, 488.3876953125, 488.371826171875, 488.3560485839844, 488.34014892578125, 488.3246154785156, 488.30865478515625, 488.2931213378906, 488.27764892578125, 488.2615661621094, 488.2456970214844, 488.23004150390625, 488.21435546875, 488.19866943359375, 488.18341064453125, 488.1673278808594, 488.15179443359375, 488.1366271972656, 488.12066650390625, 488.1048278808594, 488.0895080566406, 488.0741271972656, 488.05828857421875, 488.04266357421875, 488.0270080566406, 488.01177978515625, 487.996337890625, 487.980712890625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119872e9ca0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class regressionmodel:\n",
    "    def __init__(self):\n",
    "        self.w = torch.randn([1],requires_grad = True)\n",
    "        self.b = torch.randn([1],requires_grad = True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.w*x + self.b\n",
    "    \n",
    "    def update(self):\n",
    "        self.w -= self.w.grad*lr\n",
    "        self.b -=self.b.grad*lr\n",
    "    \n",
    "    def reset(self):\n",
    "        self.w.grad.zero_()\n",
    "        self.b.grad.zero_()\n",
    "    \n",
    "    def lossfn(self,yp,y):\n",
    "        return (yp-y)**2\n",
    "\n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0])\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "lr = torch.tensor([0.001])\n",
    "model = regressionmodel()\n",
    "losslist = []\n",
    "for epoch in range(100):\n",
    "    loss = 0\n",
    "    for i in range(len(x)):\n",
    "        yp = model.forward(x[i])\n",
    "        loss+=model.lossfn(yp,y[i])\n",
    "    loss/=len(x)\n",
    "    losslist.append(loss.item())\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.update()\n",
    "        \n",
    "    model.reset()\n",
    "\n",
    "print(losslist)\n",
    "plt.plot(losslist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7437275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30317.76953125, 13042.8291015625, 5772.1845703125, 2712.124755859375, 1424.204833984375, 882.1395263671875, 653.987060546875, 557.9542236328125, 517.5267333984375, 500.5028381347656, 493.32879638671875, 490.30047607421875, 489.0166931152344, 488.467529296875, 488.2273864746094, 488.1170959472656, 488.0616149902344, 488.0293884277344, 488.00701904296875, 487.98846435546875, 487.9715881347656, 487.9557189941406, 487.9398498535156, 487.9244689941406, 487.90863037109375, 487.8935546875, 487.87811279296875, 487.8624572753906, 487.84722900390625, 487.8316955566406, 487.81591796875, 487.8008728027344, 487.78546142578125, 487.7701721191406, 487.7547912597656, 487.739013671875, 487.72412109375, 487.7086486816406, 487.69305419921875, 487.67803955078125, 487.66278076171875, 487.64739990234375, 487.63214111328125, 487.61724853515625, 487.6016540527344, 487.58642578125, 487.5709533691406, 487.55621337890625, 487.54071044921875, 487.52569580078125, 487.51031494140625, 487.49542236328125, 487.4801330566406, 487.46484375, 487.449951171875, 487.43463134765625, 487.4195251464844, 487.40460205078125, 487.3892517089844, 487.3743591308594, 487.35906982421875, 487.34405517578125, 487.32904052734375, 487.3138732910156, 487.299072265625, 487.28350830078125, 487.26873779296875, 487.25390625, 487.2389221191406, 487.22369384765625, 487.20849609375, 487.194091796875, 487.17901611328125, 487.1639709472656, 487.1492614746094, 487.1341857910156, 487.11932373046875, 487.1041564941406, 487.08935546875, 487.0745544433594, 487.0597229003906, 487.0450134277344, 487.030029296875, 487.01531982421875, 487.000244140625, 486.98529052734375, 486.97076416015625, 486.955810546875, 486.94091796875, 486.92626953125, 486.911865234375, 486.89666748046875, 486.8821716308594, 486.86724853515625, 486.85272216796875, 486.8377990722656, 486.82281494140625, 486.80853271484375, 486.79376220703125, 486.77880859375]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self):\n",
    "        self.w = torch.randn([1], requires_grad=True)\n",
    "        self.b = torch.randn([1], requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "    def update(self, lr):\n",
    "        self.w.data -= lr * self.w.grad\n",
    "        self.b.data -= lr * self.b.grad\n",
    "\n",
    "    def reset(self):\n",
    "        self.w.grad.zero_()\n",
    "        self.b.grad.zero_()\n",
    "\n",
    "    def lossfn(self, yp, y):\n",
    "        return (yp - y).pow(2).mean()\n",
    "\n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0])\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "lr = 0.001\n",
    "model = RegressionModel()\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss = 0\n",
    "    for i in range(len(x)):\n",
    "        yp = model.forward(x[i])\n",
    "        loss += model.lossfn(yp, y[i])\n",
    "    loss /= len(x)\n",
    "    loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "\n",
    "    model.update(lr)\n",
    "    model.reset()\n",
    "\n",
    "print(loss_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee475c9a",
   "metadata": {},
   "source": [
    "# NN module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6baf4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final value of w: 12.806845664978027\n",
      "Final value of b: 2.789032459259033\n",
      "[29783.25390625, 12820.517578125, 5681.275390625, 2676.51708984375, 1411.87109375, 879.59912109375, 655.5667724609375, 561.2658081054688, 521.5656127929688, 504.84600830078125, 497.7981872558594, 494.8208923339844, 493.5572204589844, 493.0140686035156, 492.77484130859375, 492.6636657714844, 492.605712890625, 492.5701599121094, 492.5445251464844, 492.52288818359375, 492.5030822753906, 492.4837951660156, 492.46514892578125, 492.44647216796875, 492.4276428222656, 492.408935546875, 492.3907165527344, 492.37164306640625, 492.3534240722656, 492.33441162109375, 492.316162109375, 492.2972106933594, 492.27911376953125, 492.26055908203125, 492.2421875, 492.2235412597656, 492.204833984375, 492.1865234375, 492.1678771972656, 492.1495666503906, 492.13140869140625, 492.1129455566406, 492.0943298339844, 492.07586669921875, 492.05767822265625, 492.0393981933594, 492.02093505859375, 492.00274658203125, 491.9842834472656, 491.9662170410156, 491.94744873046875, 491.9291076660156, 491.9107971191406, 491.89263916015625, 491.8746032714844, 491.8563537597656, 491.83831787109375, 491.81982421875, 491.80169677734375, 491.78338623046875, 491.76519775390625, 491.7470703125, 491.7290954589844, 491.71044921875, 491.692626953125, 491.6747131347656, 491.6568298339844, 491.6385803222656, 491.6201171875, 491.60235595703125, 491.584228515625, 491.5662536621094, 491.54815673828125, 491.5299377441406, 491.5122985839844, 491.49383544921875, 491.47625732421875, 491.4580993652344, 491.4402770996094, 491.422119140625, 491.40435791015625, 491.386474609375, 491.368408203125, 491.35064697265625, 491.33282470703125, 491.31494140625, 491.29718017578125, 491.2792053222656, 491.2613830566406, 491.24365234375, 491.2259826660156, 491.20794677734375, 491.19036865234375, 491.1725158691406, 491.1546936035156, 491.1372985839844, 491.1194763183594, 491.10162353515625, 491.08404541015625, 491.06640625, 491.04876708984375, 491.03094482421875, 491.0132751464844, 490.9955139160156, 490.97821044921875, 490.96044921875, 490.9427795410156, 490.92535400390625, 490.90789794921875, 490.8902893066406, 490.8726501464844, 490.85504150390625, 490.8375549316406, 490.8199157714844, 490.80230712890625, 490.78515625, 490.76763916015625, 490.75006103515625, 490.7325134277344, 490.7149963378906, 490.6976013183594, 490.6805725097656, 490.6629943847656, 490.6455078125, 490.62811279296875, 490.61077880859375, 490.5931701660156, 490.57623291015625, 490.5589294433594, 490.5415954589844, 490.5243225097656, 490.5068359375, 490.4894104003906, 490.4720153808594, 490.4551696777344, 490.43780517578125, 490.42071533203125, 490.40325927734375, 490.38616943359375, 490.3690490722656, 490.35205078125, 490.3343200683594, 490.3175354003906, 490.300537109375, 490.2832946777344, 490.26611328125, 490.24884033203125, 490.2317810058594, 490.21466064453125, 490.19775390625, 490.18096923828125, 490.1636657714844, 490.14691162109375, 490.1294860839844, 490.1122131347656, 490.0953674316406, 490.078369140625, 490.06146240234375, 490.04437255859375, 490.0274963378906, 490.0103454589844, 489.9935607910156, 489.9765625, 489.959716796875, 489.94268798828125, 489.92633056640625, 489.9095153808594, 489.892333984375, 489.8755798339844, 489.8585510253906, 489.84210205078125, 489.8252868652344, 489.8082580566406, 489.79168701171875, 489.7748107910156, 489.75775146484375, 489.7413024902344, 489.7244567871094, 489.7078552246094, 489.6908264160156, 489.67437744140625, 489.65777587890625, 489.64093017578125, 489.62432861328125, 489.607421875, 489.59100341796875, 489.57427978515625, 489.5577087402344, 489.5411071777344, 489.524658203125, 489.508056640625, 489.4912109375, 489.47454833984375, 489.4583435058594, 489.44171142578125, 489.425048828125, 489.40863037109375, 489.39215087890625, 489.37554931640625, 489.3590393066406, 489.3426818847656, 489.32623291015625, 489.30975341796875, 489.2935485839844, 489.27691650390625, 489.26055908203125, 489.24395751953125, 489.2275390625, 489.211181640625, 489.1946716308594, 489.17840576171875, 489.1624450683594, 489.14599609375, 489.1294860839844, 489.11334228515625, 489.0966796875, 489.08038330078125, 489.06439208984375, 489.04833984375, 489.0318298339844, 489.01531982421875, 488.999267578125, 488.98309326171875, 488.967041015625, 488.9505920410156, 488.93438720703125, 488.9181213378906, 488.9020080566406, 488.8860778808594, 488.8697814941406, 488.853759765625, 488.837646484375, 488.8214416503906, 488.8055725097656, 488.78948974609375, 488.7734375, 488.75738525390625, 488.7413024902344, 488.72528076171875, 488.709228515625, 488.6932067871094, 488.6773376464844, 488.66107177734375, 488.64495849609375, 488.62921142578125, 488.6128845214844, 488.59710693359375, 488.58135986328125, 488.5650939941406, 488.54949951171875, 488.533203125, 488.51751708984375, 488.501708984375, 488.48583984375, 488.46978759765625, 488.4542541503906, 488.43829345703125, 488.4222717285156, 488.40631103515625, 488.39044189453125, 488.375, 488.3592224121094, 488.34356689453125, 488.32781982421875, 488.3121643066406, 488.29608154296875, 488.2806091308594, 488.2649841308594, 488.24920654296875, 488.2333984375, 488.217529296875, 488.2023010253906, 488.1863708496094, 488.17047119140625, 488.15521240234375, 488.13916015625, 488.12384033203125, 488.10821533203125, 488.0924377441406, 488.07666015625, 488.06134033203125, 488.045654296875, 488.0299377441406, 488.0148010253906, 487.999267578125, 487.98370361328125, 487.96826171875, 487.95233154296875, 487.9371643066406, 487.921630859375, 487.90618896484375, 487.8909606933594, 487.875244140625, 487.860107421875, 487.8443908691406, 487.82891845703125, 487.813720703125, 487.79840087890625, 487.78265380859375, 487.767333984375, 487.7523498535156, 487.73699951171875, 487.7215270996094, 487.7064514160156, 487.69091796875, 487.6754455566406, 487.66015625, 487.64483642578125, 487.6297302246094, 487.6145935058594, 487.5989685058594, 487.5840759277344, 487.56878662109375, 487.553466796875, 487.53839111328125, 487.5230407714844, 487.5077209472656, 487.49261474609375, 487.4775390625, 487.46221923828125, 487.44732666015625, 487.4320373535156, 487.41693115234375, 487.40203857421875, 487.38671875, 487.3716735839844, 487.35675048828125, 487.34136962890625, 487.3265075683594, 487.3113708496094, 487.2962341308594, 487.28155517578125, 487.2662658691406, 487.2515563964844, 487.23614501953125, 487.2215881347656, 487.2062072753906, 487.1914978027344, 487.1766052246094, 487.16168212890625, 487.1465759277344, 487.131591796875, 487.116455078125, 487.1019592285156, 487.0869140625, 487.0719299316406, 487.0572204589844, 487.0423889160156, 487.0274963378906, 487.0128479003906, 486.9978942871094, 486.98297119140625, 486.96832275390625, 486.95330810546875, 486.9388122558594, 486.923828125, 486.90911865234375, 486.8941345214844, 486.879638671875, 486.8646545410156, 486.8501892089844, 486.835205078125, 486.8208923339844, 486.80615234375, 486.79119873046875, 486.77685546875, 486.7620544433594, 486.74737548828125, 486.7325744628906, 486.7181701660156, 486.7035217285156, 486.68878173828125, 486.6739807128906, 486.6592712402344, 486.6449279785156, 486.6304626464844, 486.6158752441406, 486.601318359375, 486.5869140625, 486.57220458984375, 486.5576171875, 486.5433044433594, 486.5287170410156, 486.51422119140625, 486.49981689453125, 486.48565673828125, 486.47064208984375, 486.45648193359375, 486.44183349609375, 486.4276428222656, 486.4134216308594, 486.39874267578125, 486.3841247558594, 486.3699645996094, 486.3556213378906, 486.34100341796875, 486.3268127441406, 486.3124084472656, 486.2978515625, 486.28363037109375, 486.26934814453125, 486.25494384765625, 486.24078369140625, 486.2265625, 486.21221923828125, 486.19818115234375, 486.18389892578125, 486.1695251464844, 486.1552734375, 486.14129638671875, 486.126708984375, 486.11285400390625, 486.0985412597656, 486.0841369628906, 486.0701599121094, 486.05621337890625, 486.0419921875, 486.02764892578125, 486.01336669921875, 485.9991760253906, 485.98541259765625, 485.97119140625, 485.9569396972656, 485.94305419921875, 485.9288024902344, 485.9146423339844, 485.90057373046875, 485.8868103027344, 485.87261962890625, 485.8585510253906, 485.8445739746094, 485.8304748535156, 485.8167419433594, 485.80279541015625, 485.7887268066406, 485.7747497558594, 485.76080322265625, 485.7469787597656, 485.733154296875, 485.7188415527344, 485.70526123046875, 485.6910095214844, 485.67742919921875, 485.6629333496094, 485.64959716796875, 485.63531494140625, 485.6219177246094, 485.60772705078125, 485.5938415527344, 485.58001708984375, 485.56634521484375, 485.55279541015625, 485.5387268066406, 485.5249938964844, 485.5110778808594, 485.49700927734375, 485.483642578125, 485.469970703125, 485.4561462402344, 485.442138671875, 485.42840576171875, 485.41497802734375, 485.40130615234375, 485.38775634765625, 485.3736877441406, 485.3597717285156, 485.3462829589844, 485.33294677734375, 485.31903076171875, 485.30548095703125, 485.291748046875, 485.27825927734375, 485.2647399902344, 485.25079345703125, 485.237548828125, 485.2236328125, 485.2100524902344, 485.19677734375, 485.18304443359375, 485.16961669921875, 485.15606689453125, 485.14239501953125, 485.12908935546875, 485.115478515625, 485.1019592285156, 485.0884704589844, 485.07501220703125, 485.0615234375, 485.048095703125, 485.03466796875, 485.02142333984375, 485.00799560546875, 484.9940490722656, 484.98095703125, 484.96746826171875, 484.9539489746094, 484.94091796875, 484.92742919921875, 484.91400146484375, 484.90081787109375, 484.88714599609375, 484.8736267089844, 484.86077880859375, 484.8472595214844, 484.833984375, 484.8209533691406, 484.80731201171875, 484.7940979003906, 484.7809143066406, 484.7676696777344, 484.7543029785156, 484.7410583496094, 484.72772216796875, 484.71484375, 484.70135498046875, 484.68817138671875, 484.67486572265625, 484.66180419921875, 484.6487731933594, 484.63580322265625, 484.6224060058594, 484.60906982421875, 484.595947265625, 484.58306884765625, 484.5699768066406, 484.55657958984375, 484.543701171875, 484.5302734375, 484.5176696777344, 484.5042419433594, 484.4913635253906, 484.47802734375, 484.46527099609375, 484.45172119140625, 484.4390563964844, 484.4259338378906, 484.4129943847656, 484.39996337890625, 484.3868103027344, 484.3739318847656, 484.361328125, 484.3480529785156, 484.33526611328125, 484.32232666015625, 484.30908203125, 484.29620361328125, 484.28326416015625, 484.27044677734375, 484.257568359375, 484.2445373535156, 484.2315979003906, 484.21875, 484.206298828125, 484.19329833984375, 484.18011474609375, 484.1673889160156, 484.1543884277344, 484.14202880859375, 484.1290588378906, 484.1160583496094, 484.103515625, 484.0904846191406, 484.07763671875, 484.06494140625, 484.0523986816406, 484.03961181640625, 484.026611328125, 484.0140075683594, 484.0016174316406, 483.988525390625, 483.9759216308594, 483.96307373046875, 483.95050048828125, 483.9378967285156, 483.92535400390625, 483.9125061035156, 483.89971923828125, 483.8872985839844, 483.8749084472656, 483.86212158203125, 483.8492736816406, 483.83685302734375, 483.82403564453125, 483.81146240234375, 483.7989807128906, 483.78619384765625, 483.7738342285156, 483.760986328125, 483.748779296875, 483.7359924316406, 483.72369384765625, 483.71087646484375, 483.6988830566406, 483.68597412109375, 483.673583984375, 483.6610412597656, 483.6485900878906, 483.6360778808594, 483.62371826171875, 483.61102294921875, 483.59881591796875, 483.58660888671875, 483.573974609375, 483.561279296875, 483.54901123046875, 483.536376953125, 483.5240783691406, 483.51177978515625, 483.49945068359375, 483.4872131347656, 483.4747619628906, 483.462646484375, 483.4501037597656, 483.4375915527344, 483.42559814453125, 483.41302490234375, 483.40081787109375, 483.3887634277344, 483.3760681152344, 483.364013671875, 483.35150146484375, 483.3395080566406, 483.3269958496094, 483.3152770996094, 483.302734375, 483.29034423828125, 483.27825927734375, 483.2659606933594, 483.25372314453125, 483.24176025390625, 483.22955322265625, 483.21728515625, 483.20501708984375, 483.19281005859375, 483.1807556152344, 483.1685485839844, 483.15679931640625, 483.144287109375, 483.1322326660156, 483.1202697753906, 483.10797119140625, 483.0960998535156, 483.08416748046875, 483.0716857910156, 483.05975341796875, 483.04766845703125, 483.0354919433594, 483.0235900878906, 483.01165771484375, 482.99981689453125, 482.9874572753906, 482.97589111328125, 482.963623046875, 482.95147705078125, 482.9396057128906, 482.92755126953125, 482.91552734375, 482.90350341796875, 482.891845703125, 482.87994384765625, 482.8680114746094, 482.8560485839844, 482.84429931640625, 482.8323669433594, 482.820556640625, 482.8084411621094, 482.7967224121094, 482.7848205566406, 482.7728576660156, 482.7608337402344, 482.7489318847656, 482.7373046875, 482.725341796875, 482.71337890625, 482.70184326171875, 482.6902770996094, 482.6781311035156, 482.6665954589844, 482.6543884277344, 482.6426696777344, 482.6310119628906, 482.6194763183594, 482.607666015625, 482.59588623046875, 482.5843200683594, 482.57232666015625, 482.560546875, 482.54901123046875, 482.53729248046875, 482.525390625, 482.5140686035156, 482.50225830078125, 482.4906311035156, 482.47906494140625, 482.46722412109375, 482.45562744140625, 482.4440002441406, 482.4322204589844, 482.42041015625, 482.40924072265625, 482.39752197265625, 482.3858337402344, 482.3746032714844, 482.36260986328125, 482.35113525390625, 482.3397521972656, 482.327880859375, 482.31646728515625, 482.3047790527344, 482.29345703125, 482.28179931640625, 482.2704162597656, 482.2589416503906, 482.24749755859375, 482.23590087890625, 482.2247009277344, 482.21282958984375, 482.201416015625, 482.190185546875, 482.17877197265625, 482.16729736328125, 482.1558532714844, 482.1443786621094, 482.13287353515625, 482.1214904785156, 482.1099548339844, 482.0986328125, 482.0873107910156, 482.0758361816406, 482.064453125, 482.0533752441406, 482.04229736328125, 482.03057861328125, 482.01922607421875, 482.00811767578125, 481.99639892578125, 481.985107421875, 481.97406005859375, 481.96295166015625, 481.95123291015625, 481.9403381347656, 481.92889404296875, 481.91778564453125, 481.90618896484375, 481.89495849609375, 481.8841247558594, 481.8726501464844, 481.861328125, 481.8502502441406, 481.83892822265625, 481.82763671875, 481.8164978027344, 481.80548095703125, 481.79425048828125, 481.78289794921875, 481.77203369140625, 481.7607421875, 481.74957275390625, 481.73846435546875, 481.727294921875, 481.7162170410156, 481.7051696777344, 481.69403076171875, 481.6829528808594, 481.67156982421875, 481.66082763671875, 481.6495056152344, 481.63836669921875, 481.627685546875, 481.61651611328125, 481.60528564453125, 481.59442138671875, 481.58331298828125, 481.5724182128906, 481.5613708496094, 481.55047607421875, 481.5391540527344, 481.5281677246094, 481.5174255371094, 481.5061950683594, 481.4954528808594, 481.4845275878906, 481.47357177734375, 481.46234130859375, 481.451416015625, 481.44061279296875, 481.4296875, 481.41888427734375, 481.40814208984375, 481.39703369140625, 481.38616943359375, 481.3753967285156, 481.36419677734375, 481.35345458984375, 481.3426208496094, 481.331787109375, 481.32098388671875, 481.31011962890625, 481.29925537109375, 481.2886657714844, 481.27764892578125, 481.26702880859375, 481.25628662109375, 481.24517822265625, 481.234619140625, 481.2235412597656, 481.2129821777344, 481.20220947265625, 481.19158935546875, 481.1805114746094, 481.16986083984375, 481.1592712402344, 481.1483459472656, 481.1376037597656, 481.12677001953125, 481.11614990234375, 481.1053771972656, 481.0950622558594, 481.08447265625, 481.07366943359375, 481.0630798339844, 481.0521545410156, 481.04150390625, 481.0311584472656, 481.0203552246094, 481.00982666015625, 480.9991149902344, 480.9884338378906, 480.977783203125, 480.967529296875, 480.95684814453125, 480.9459533691406, 480.93572998046875, 480.925048828125, 480.9143981933594, 480.9037170410156, 480.8937072753906, 480.8829040527344, 480.87213134765625, 480.86187744140625, 480.85113525390625, 480.84088134765625, 480.83026123046875, 480.81982421875, 480.80963134765625, 480.7986755371094, 480.78851318359375, 480.77764892578125, 480.7677307128906, 480.75689697265625, 480.74658203125, 480.7362365722656, 480.7257385253906, 480.7154235839844, 480.7049255371094, 480.69464111328125, 480.68408203125, 480.673583984375, 480.66326904296875, 480.6529846191406, 480.64251708984375, 480.63226318359375, 480.6219177246094, 480.61163330078125, 480.60107421875, 480.5908203125, 480.5804138183594, 480.56988525390625, 480.5599060058594, 480.54974365234375, 480.5392150878906, 480.52886962890625, 480.51873779296875, 480.50830078125, 480.4981994628906, 480.488037109375, 480.47772216796875, 480.467041015625, 480.4569396972656, 480.4471740722656, 480.4366760253906, 480.4264221191406, 480.41644287109375, 480.4060974121094, 480.3959045410156, 480.38568115234375, 480.37579345703125, 480.3653259277344, 480.355224609375, 480.34503173828125, 480.33477783203125, 480.32501220703125, 480.3146057128906, 480.30426025390625, 480.29425048828125, 480.2841796875, 480.2740173339844, 480.2640686035156, 480.2539978027344, 480.2435607910156, 480.2337951660156, 480.22357177734375, 480.2137756347656, 480.20330810546875, 480.1934509277344, 480.1834411621094, 480.17340087890625, 480.1632385253906, 480.1532287597656, 480.14324951171875, 480.13348388671875, 480.1234436035156, 480.11322021484375, 480.10296630859375, 480.09332275390625, 480.08355712890625, 480.073486328125, 480.0633850097656, 480.0533142089844, 480.0436096191406, 480.0335998535156, 480.0238342285156, 480.013916015625, 480.00408935546875, 479.9938049316406, 479.98394775390625, 479.9739685058594, 479.96435546875, 479.9544982910156, 479.9441833496094, 479.93438720703125, 479.9248046875, 479.9146423339844, 479.9046936035156, 479.8951721191406, 479.88531494140625, 479.8756408691406, 479.86566162109375, 479.85601806640625, 479.845703125, 479.83642578125, 479.82635498046875, 479.81640625, 479.80712890625, 479.7969665527344, 479.787109375, 479.77728271484375, 479.767578125, 479.75762939453125, 479.7481384277344, 479.7384338378906, 479.72869873046875, 479.7191467285156, 479.70947265625, 479.69964599609375, 479.69000244140625, 479.68048095703125, 479.6705017089844, 479.6609802246094, 479.65142822265625, 479.6412658691406, 479.63189697265625, 479.62237548828125, 479.61279296875, 479.60302734375, 479.5933532714844, 479.58367919921875, 479.57403564453125, 479.5646057128906, 479.55517578125, 479.54522705078125, 479.535888671875, 479.5259704589844, 479.5165100097656, 479.50714111328125, 479.49737548828125, 479.48773193359375, 479.4783630371094, 479.46856689453125, 479.45941162109375, 479.4498596191406, 479.4402770996094, 479.43060302734375, 479.4208068847656, 479.41156005859375, 479.4019470214844, 479.3929748535156, 479.3832092285156, 479.37371826171875, 479.3641662597656, 479.3546447753906, 479.34527587890625, 479.3358459472656, 479.3265075683594, 479.3169860839844, 479.30780029296875, 479.29815673828125, 479.28887939453125, 479.27935791015625, 479.2698669433594]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.w = torch.randn([1], requires_grad=True)\n",
    "        self.b = torch.randn([1], requires_grad=True)\n",
    "        self.optimizer = optim.SGD([self.w, self.b], lr=learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "    def fit(self, x, y, num_epochs=1000):\n",
    "        loss_list = []\n",
    "        for epoch in range(num_epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            preds = self.forward(x)\n",
    "            loss = self.criterion(preds, y)\n",
    "            loss.backward()\n",
    "            loss_list.append(loss.item())\n",
    "            self.optimizer.step()\n",
    "        final_preds = (self.w * x + self.b).detach().numpy()\n",
    "        return loss_list, final_preds\n",
    "\n",
    "# Example usage:\n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0])\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0])\n",
    "\n",
    "model = LinearRegression()\n",
    "loss_list, final_preds = model.fit(x, y, num_epochs=1000)\n",
    "\n",
    "# Print final values of w and b\n",
    "print(\"Final value of w:\", model.w.item())\n",
    "print(\"Final value of b:\", model.b.item())\n",
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a728834",
   "metadata": {},
   "source": [
    "# Reg with input dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7cfd94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight\n",
      "tensor([[12.9584]])\n",
      "linear.bias\n",
      "tensor([0.5830])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TrueLinearRegression(nn.Module):\n",
    "    def __init__(self, input_dims, learning_rate=0.001):\n",
    "        super(TrueLinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, 1)  # Corrected the typo in the linear layer\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def fit(self, x, y, num_epochs=100, plot=True):\n",
    "        losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            preds = self.forward(x)\n",
    "            loss = self.criterion(preds, y)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item()) \n",
    "            self.optimizer.step()\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            print(name)\n",
    "            print(param.data)\n",
    "\n",
    "# Example usage:\n",
    "x = torch.tensor([5.0, 7.0, 12.0, 16.0, 20.0], dtype=torch.float32).view(-1, 1)\n",
    "y = torch.tensor([40.0, 120.0, 180.0, 210.0, 240.0], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "model = TrueLinearRegression(input_dims=1)\n",
    "model.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac469d",
   "metadata": {},
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8532d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XORModel(\n",
      "  (linear1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation1): Sigmoid()\n",
      "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1000/10000, Loss = 0.27266925573349\n",
      "Epoch 2000/10000, Loss = 0.27059854939579964\n",
      "Epoch 3000/10000, Loss = 0.26853587478399277\n",
      "Epoch 4000/10000, Loss = 0.2639296129345894\n",
      "Epoch 5000/10000, Loss = 0.22337761893868446\n",
      "Epoch 6000/10000, Loss = 0.0001427828324267466\n",
      "Epoch 7000/10000, Loss = 1.2214229627716122e-11\n",
      "Epoch 8000/10000, Loss = 3.1867841698840493e-12\n",
      "Epoch 9000/10000, Loss = 3.1867841698840493e-12\n",
      "Epoch 10000/10000, Loss = 3.1867841698840493e-12\n",
      "linear1.weight: tensor([[-1.9767,  2.0750],\n",
      "        [-3.0809,  3.3435]])\n",
      "linear1.bias: tensor([ 0.7012, -2.5002])\n",
      "linear2.weight: tensor([[-2.6653,  2.7713]])\n",
      "linear2.bias: tensor([1.5715])\n",
      "Input = tensor([0., 1.])\n",
      "Output = tensor([1.0000], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_list = []\n",
    "torch.manual_seed(42)\n",
    "\n",
    "x = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([0, 1, 1, 0], dtype=torch.float32)\n",
    "\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(2, 2, bias=True)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(2, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "dataset = MyDataset(x, y)\n",
    "batch_size = 1\n",
    "train_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = XORModel().to(device)\n",
    "print(model)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03)\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.flatten(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / (len(train_data_loader) * batch_size)\n",
    "\n",
    "EPOCHS = 10000\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "    loss_list.append(avg_loss)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}, Loss = {avg_loss}\")\n",
    "\n",
    "# Print weights and biases\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n",
    "\n",
    "input_data = torch.tensor([0., 1.]).to(device)\n",
    "model.eval()\n",
    "print(\"Input =\", input_data)\n",
    "print(\"Output =\", model(input_data))\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca08cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 9912422/9912422 [00:04<00:00, 2168691.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 28881/28881 [00:00<00:00, 7884898.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1648877/1648877 [00:00<00:00, 2295657.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.305\n",
      "[1,   200] loss: 2.295\n",
      "[1,   300] loss: 2.287\n",
      "[1,   400] loss: 2.276\n",
      "[1,   500] loss: 2.249\n",
      "[1,   600] loss: 2.198\n",
      "[1,   700] loss: 2.095\n",
      "[1,   800] loss: 1.908\n",
      "[1,   900] loss: 1.650\n",
      "[1,  1000] loss: 1.370\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14636\\2679775624.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(64,128,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                 nn.Conv2d(128,64,3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.MaxPool2d((2,2),stride=2),\n",
    "                                )\n",
    "        self.classification_head = nn.Sequential(nn.Linear(64,20,bias=True),\n",
    "                                                 nn.ReLU(),\n",
    "                                                 nn.Linear(20,10,bias=True),)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        features = self.net(x)\n",
    "        return self.classification_head(features.view(batch_size,-1))\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root=\"./data\",download = True,train=True,transform=ToTensor())\n",
    "train_loader = DataLoader(mnist_trainset,batch_size=50,shuffle=True)\n",
    "mnist_testset = datasets.MNIST(root=\"./data\",download = True,train=False,transform=ToTensor())\n",
    "test_loader = DataLoader(mnist_testset,batch_size=50,shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "batch_size=50\n",
    "\n",
    "total_params = 0\n",
    "for name,param in model.named_parameters():\n",
    "    params = param.numel()\n",
    "    total_params += params\n",
    "\n",
    "for epoch in range(6):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(f\"Finished Training. Final loss = {loss.item()}, Total params = {total_params}\")\n",
    "\n",
    "correct,total = 0,0\n",
    "for i,vdata in enumerate(test_loader):\n",
    "    tinputs,tlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "    toutputs = model(tinputs)\n",
    "\n",
    "    _,predicted = torch.max(toutputs,1)\n",
    "    total += tlabels.size(0)\n",
    "    correct += (predicted==tlabels).sum()\n",
    "        \n",
    "print(f\"Correct = {correct}, Total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b631d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
